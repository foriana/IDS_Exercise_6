---
title: 'Weekly Exercises #6'
author: "Felicia Peterson"
output: 
  html_document:
    keep_md: TRUE
    toc: TRUE
    toc_float: TRUE
    df_print: paged
    code_download: true
---


```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE, error=TRUE, message=FALSE, warning=FALSE)
```

```{r libraries}
library(tidyverse)     # for data cleaning and plotting
library(gardenR)       # for Lisa's garden data
library(lubridate)     # for date manipulation
library(openintro)     # for the abbr2state() function
library(palmerpenguins)# for Palmer penguin data
library(maps)          # for map data
library(ggmap)         # for mapping points on maps
library(gplots)        # for col2hex() function
library(RColorBrewer)  # for color palettes
library(sf)            # for working with spatial data
library(leaflet)       # for highly customizable mapping
library(ggthemes)      # for more themes (including theme_map())
library(plotly)        # for the ggplotly() - basic interactivity
library(gganimate)     # for adding animation layers to ggplots
library(gifski)        # for creating the gif (don't need to load this library every time,but need it installed)
library(transformr)    # for "tweening" (gganimate)
library(shiny)         # for creating interactive apps
library(patchwork)     # for nicely combining ggplot2 graphs  
library(gt)            # for creating nice tables
library(rvest)         # for scraping data
library(robotstxt)     # for checking if you can scrape data
library(countrycode)
theme_set(theme_minimal())
```

```{r data}
# Lisa's garden data
data("garden_harvest")

#COVID-19 data from the New York Times
covid19 <- read_csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv")

#Olympic medal data
olympics <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-07-27/olympics.csv')

```

## Put your homework on GitHub!

Go [here](https://github.com/llendway/github_for_collaboration/blob/master/github_for_collaboration.md) or to previous homework to remind yourself how to get set up. 

Once your repository is created, you should always open your **project** rather than just opening an .Rmd file. You can do that by either clicking on the .Rproj file in your repository folder on your computer. Or, by going to the upper right hand corner in R Studio and clicking the arrow next to where it says Project: (None). You should see your project come up in that list if you've used it recently. You could also go to File --> Open Project and navigate to your .Rproj file. 

## Instructions

* Put your name at the top of the document. 

* **For ALL graphs, you should include appropriate labels.** 

* Feel free to change the default theme, which I currently have set to `theme_minimal()`. 

* Use good coding practice. Read the short sections on good code with [pipes](https://style.tidyverse.org/pipes.html) and [ggplot2](https://style.tidyverse.org/ggplot2.html). **This is part of your grade!**

* **NEW!!** With animated graphs, add `eval=FALSE` to the code chunk that creates the animation and saves it using `anim_save()`. Add another code chunk to reread the gif back into the file. See the [tutorial](https://animation-and-interactivity-in-r.netlify.app/) for help. 

* When you are finished with ALL the exercises, uncomment the options at the top so your document looks nicer. Don't do it before then, or else you might miss some important warnings and messages.


## Warm-up exercises from tutorial

1. Read in the fake garden harvest data. Find the data [here](https://github.com/llendway/scraping_etc/blob/main/2020_harvest.csv) and click on the `Raw` button to get a direct link to the data. After reading in the data, do one of the quick checks mentioned in the tutorial.

```{r}

X2020_harvest <- read_csv("https://raw.githubusercontent.com/llendway/scraping_etc/main/2020_harvest.csv", 
    col_types = cols(...1 = col_skip(), date = col_date(format = "%m/%d/%y"), 
        weight = col_number()), skip = 2)
paths_allowed(paths = "https://github.com/llendway/scraping_etc/blob/main/2020_harvest.csv")


```

  
2. Read in this [data](https://www.kaggle.com/heeraldedhia/groceries-dataset) from the kaggle website. You will need to download the data first. Save it to your project/repo folder. Do some quick checks of the data to assure it has been read in appropriately.

```{r}

Groceries_dataset <- read_csv("C:/Users/JoyFP/Downloads/kaggle_gaggle/Groceries_dataset.csv", 
    col_types = cols(Date = col_character())) %>% 
  mutate(Date = dmy(Date))

paths_allowed(paths = "https://www.kaggle.com/datasets/heeraldedhia/groceries-dataset?resource=download") 


```

3. Create a table using `gt` with data from your project or from the `garden_harvest` data if your project data aren't ready. Use at least 3 `gt()` functions.

```{r}
golden_medal <- olympics %>% 
  drop_na(medal) %>% 
  filter(medal == "Gold") %>% 
  group_by(noc) %>% 
  count(medal) %>% 
  arrange(desc(n))
 
golden_medal
 
  
```

```{r}
#golden_medal %>% 
  #gt(rowname_col = "noc") %>% 
 # tab_row_group(label = "Shiny Boys", 
           #     rows = n > 100) 

```

4. CHALLENGE (not graded): Write code to replicate the table shown below (open the .html file to see it) created from the `garden_harvest` data as best as you can. When you get to coloring the cells, I used the following line of code for the `colors` argument:
  
```{r, eval=FALSE}
colors = scales::col_numeric(
      palette = paletteer::paletteer_d(
        palette = "RColorBrewer::YlGn"
      ) %>% as.character()
      
soup_ingredients <- garden_harvest %>% 
  filter(vegetable == "beans" | vegetable == "carrots" | vegetable == "tomatoes") %>% 
  mutate(soupy_bois = str_to_title(vegetable)) %>% 
  group_by(soupy_bois, variety) %>% 
  summarize(weight = sum(weight)) %>% 
  mutate(weight =  weight * 0.00220462) %>% 
  arrange(desc(weight)) %>% 
  arrange(soupy_bois)
```


```{r}
soup_ingredients %>% 
  gt() %>% 
  data_color(
    colors = scales::col_numeric(
      palette = paletteer::paletteer_d(
        palette = "RColorBrewer::YlGn"
      ) %>% as.character()
  ))
  
  

```

  
5. Use `patchwork` operators and functions to combine at least two graphs using your project data or `garden_harvest` data if your project data aren't read.

```{r}
#fig.height=, fig.width=
world <- map_data("world")


gold_map <- golden_medal %>%
  mutate(countryName = countrycode(noc, "genc3c", "country.name")) %>%
  mutate(countryName = ifelse(countryName == "USA", "United States", countryName)) %>% 
  ggplot() +
  geom_map(map = world, 
           aes(map_id = countryName,
               fill = n)) +
  scale_fill_gradient(low=cm.colors(20)[1], high=cm.colors(20)[20])+
  expand_limits(x = world$long, y = world$lat) +
  theme(legend.position = "bottom") +
  theme_map()

top_figure_skaters <- olympics %>% 
   drop_na(medal) %>% 
  filter(medal == "Gold",
         str_detect(event, "Figure")) %>% 
   mutate(countryName = countrycode(noc, "genc3c", "country.name")) %>%
   mutate(countryName = ifelse(countryName == "USA", "United States", countryName)) %>% 
  filter(countryName %in% c("Austria", "Canada", "Russia", "United States" )) %>% 
  group_by(countryName, year, medal, sport) %>% 
   count(medal)

five_gold_skates <- top_figure_skaters %>% 
  ggplot(aes(x = year,
            y = n, 
            color = countryName)) +
  geom_line() + 
  labs(title = "Top 5 Countries in Olympic Figure Skating Competitions",
       subtitle = "Cumulative Gold Medal Counts",
       y = "",
       x = "")

general_skate <- olympics %>% 
  drop_na(medal) %>% 
  filter(medal == "Gold",
         str_detect(event, "Figure")) %>% 
   mutate(countryName = countrycode(noc, "genc3c", "country.name")) %>%
   mutate(countryName = ifelse(countryName == "USA", "United States", countryName)) %>% 
  group_by(countryName, medal, sport) %>% 
  drop_na(countryName) %>% 
   count(medal)


go_figure <- general_skate %>% 
  ggplot(aes(x = n, 
             y = fct_reorder(countryName, n, .desc = FALSE),
             fill = countryName)) +
  geom_col() +
  labs(title = "Total Figure Skating Olympic Gold Medals",
       y = "",
       x = "") +
  theme(legend.position = "none")

go_figure + (gold_map/five_gold_skates) +
  plot_annotation(title = "Olympic Gold Medals, emphasis on figure skating")

  

```

## Webscraping exercise (also from tutorial)

Use the data from the [Macalester Registrar's Fall 2017 Class Schedule](https://www.macalester.edu/registrar/schedules/2017fall/class-schedule/#crs10008) to complete all these exercises.

6. Find the correct selectors for the following fields. Make sure that each matches 762 results:

  * Course Number
  * Course Name
  * Day
  * Time
  * Room
  * Instructor
  * Avail. / Max
  * General Education Requirements (make sure you only match 762; beware of the Mac copyright banner at the bottom of the page!)
  * Description

Then, put all this information into one dataset (tibble or data.frame) Do not include any extraneous information like "Instructor: ".

```{r}
fall2017 <- read.csv("https://www.macalester.edu/registrar/schedules/2017fall/class-schedule#crs10008")

course_nums <-
  fall2017 %>% 
  html_elements(".class-schedule-course-number") %>% 
  html_text2()
head(course_nums)

course_names <- 
  fall2017 %>%
  html_elements(".class-schedule-course-title") %>%
  html_text2()
head(course_names)

course_days <- 
  fall2017 %>%
  html_elements("td.class-schedule-label:nth-child(3)") %>% 
  html_text2() %>% 
  str_sub(start = 7)
head(course_days)

course_time <-
  fall2017 %>% 
  html_elements(".class-schedule-label:nth-child(4)") %>% 
  html_text2()
head(course_time)

course_room <-
  fall2017 %>% 
  html_elements(".class-schedule-label:nth-child(5)") %>% 
  html_text2()
head(course_room)

course_instructor <-
  fall2017 %>% 
  html_elements(".class-schedule-label:nth-child(6)") %>% 
  html_text2()
head(course_instructor)

course_seats <-
  fall2017 %>% 
  html_elements(".class-schedule-label:nth-child(7) ") %>% 
  html_text2()
head(course_seats)

course_gened <-
  fall2017 %>% 
  html_elements("p:nth-child(2)") %>% 
  html_text2()
head(course_gened)

course_desc <-
  fall2017 %>% 
  html_elements(".collapsed p:nth-child(1)") %>% 
  html_text2()
head(course_desc)


#course_df <- tibble(number=course_nums, name=course_names)
#head(course_df)

```
  

7. Create a graph that shows the number of sections offered per department. Hint: The department is a substring of the course number - there are `str_XXX()` functions that can help. Yes, COMP and MATH are the same department, but for this exercise you can just show the results by four letter department code, e.g., with COMP and MATH separate.


8. Analyze the typical length of course names by department. To do so, create a new data table based on your courses data table, with the following changes:
  
  * New columns for the length of the title of a course and the length of the description of the course. Hint: `str_length`.  
  * Remove departments that have fewer than 10 sections of courses. To do so, group by department, then remove observations in groups with fewer than 10 sections (Hint: use filter with n()). Then `ungroup()` the data.  
  * Create a visualization of the differences across groups in lengths of course names or course descriptions. Think carefully about the visualization you should be using!


  

**DID YOU REMEMBER TO UNCOMMENT THE OPTIONS AT THE TOP?**
